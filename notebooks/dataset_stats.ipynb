{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "democratic-pickup",
   "metadata": {},
   "source": [
    "## Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ideal-republican",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/aliak/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/aliak/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation, TruncatedSVD\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "import string\n",
    "import re\n",
    "import nltk, razdel\n",
    "from nltk.corpus import stopwords\n",
    "from pymystem3 import Mystem\n",
    "\n",
    "# Download nltk packages used in this example\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "consecutive-handling",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('../dataset/enumerated_shuffled_rbc.json')\n",
    "df = df.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "derived-alert",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customize list of stopwords as needed. Here, we append common\n",
    "# punctuation and contraction artifacts.\n",
    "with open('../aux/stopwords-ru.txt', 'r') as f:\n",
    "    ru_stop_words_extensive = f.read().splitlines()\n",
    "    \n",
    "punctuations = list(string.punctuation) + [\"—\", \"«\", \"»\", \"\\n\"]\n",
    "stop_words = list(set(ru_stop_words_extensive + stopwords.words('russian'))) + punctuations\n",
    "\n",
    "\n",
    "\n",
    "def get_normalized_sentences(doc):\n",
    "    doc = re.sub(r\"[^а-яА-Я]\", \" \", doc, re.I|re.A)\n",
    "    doc = doc.lower()\n",
    "    doc = doc.strip()\n",
    "    sentences = get_article_sentences(doc)\n",
    "    return sentences\n",
    "    \n",
    "    \n",
    "def get_article_sentences(article_text):\n",
    "    sentences = list()\n",
    "    for sentence in razdel.sentenize(article_text):\n",
    "        sentences.append(sentence.text)\n",
    "    return sentences\n",
    "\n",
    "def get_article_tokens(article_sentences):\n",
    "    tokens = list()\n",
    "    for sentence in article_sentences:\n",
    "        for token in razdel.tokenize(sentence):\n",
    "            if token.text not in stop_words:\n",
    "                tokens.append(token.text.lower().strip())\n",
    "    return tokens\n",
    "\n",
    "def get_article_lemmas(article_sentences):\n",
    "    mystem = Mystem()\n",
    "    lemmas = list()\n",
    "    for sentence in article_sentences:\n",
    "        sentence_lemmas = mystem.lemmatize(sentence.lower())\n",
    "        sentence_lemmas = [lemma for lemma in sentence_lemmas if lemma not in stop_words\\\n",
    "          and lemma != \" \"\\\n",
    "          and not lemma.isdigit()\n",
    "          and lemma.strip() not in punctuations]\n",
    "    lemmas+=sentence_lemmas\n",
    "    return lemmas\n",
    "\n",
    "def normalize_document(doc):\n",
    "    # lower case and remove special characters\\whitespaces\n",
    "    doc = re.sub(r\"[^а-яА-Я]\", \" \", doc, re.I|re.A)\n",
    "    doc = doc.lower()\n",
    "    doc = doc.strip()\n",
    "    sentences = get_article_sentences(doc)\n",
    "    # tokenize document\n",
    "    lemmas, unique_lemmas = get_article_lemmas(sentences)\n",
    "    #filter stopwords out of document\n",
    "    tokens, unique_tokens = get_article_tokens(sentences)\n",
    "    # re-create document from filtered tokens\n",
    "    doc = ' '.join(lemmas)\n",
    "    return doc, \n",
    "\n",
    "normalize_corpus = np.vectorize(normalize_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "above-sodium",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1606"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = normalize_corpus(list(df['article_text']))\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "minute-delay",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>article_overview</th>\n",
       "      <th>article_text</th>\n",
       "      <th>category</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Песков заявил об отсутствии соглашений по укра...</td>\n",
       "      <td>Об отправке 11 вагонов с зерном для продажи со...</td>\n",
       "      <td>Об отправке 11 вагонов с зерном для продажи ...</td>\n",
       "      <td>politics</td>\n",
       "      <td>[Украина, зерно, поставки, переговоры]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>В Киеве попросили уточнить слова Байдена об от...</td>\n",
       "      <td>Западные страны не стали вводить превентивные ...</td>\n",
       "      <td>Западные страны не стали вводить превентивны...</td>\n",
       "      <td>politics</td>\n",
       "      <td>[Украина, Джо Байден, санкции, Владимир Зеленс...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Владелец бондов «Роснано» назвал возможный деф...</td>\n",
       "      <td>По мнению гендиректора «Арикапитала», если гос...</td>\n",
       "      <td>По мнению гендиректора «Арикапитала», если г...</td>\n",
       "      <td>economics</td>\n",
       "      <td>[«Роснано», дефолт, облигации, рублевые облига...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  \\\n",
       "0  Песков заявил об отсутствии соглашений по укра...   \n",
       "1  В Киеве попросили уточнить слова Байдена об от...   \n",
       "2  Владелец бондов «Роснано» назвал возможный деф...   \n",
       "\n",
       "                                    article_overview  \\\n",
       "0  Об отправке 11 вагонов с зерном для продажи со...   \n",
       "1  Западные страны не стали вводить превентивные ...   \n",
       "2  По мнению гендиректора «Арикапитала», если гос...   \n",
       "\n",
       "                                        article_text   category  \\\n",
       "0    Об отправке 11 вагонов с зерном для продажи ...   politics   \n",
       "1    Западные страны не стали вводить превентивны...   politics   \n",
       "2    По мнению гендиректора «Арикапитала», если г...  economics   \n",
       "\n",
       "                                                tags  \n",
       "0             [Украина, зерно, поставки, переговоры]  \n",
       "1  [Украина, Джо Байден, санкции, Владимир Зеленс...  \n",
       "2  [«Роснано», дефолт, облигации, рублевые облига...  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "african-gasoline",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = \\\n",
    "              np.split(df.sample(frac=1, random_state=777), \n",
    "                       [int(.6*len(df)), int(.8*len(df))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "educated-february",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_per_group(df):\n",
    "    \n",
    "    results = pd.DataFrame()\n",
    "    words_for_all_headlines = []\n",
    "    lemmas_for_all_headlines = []\n",
    "    words_for_all_articles = []\n",
    "    lemmas_for_all_articles = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        \n",
    "        headline = df['headline'][index]\n",
    "        norm_headline = get_normalized_sentences(headline)\n",
    "        headline_words = get_article_tokens(norm_headline)\n",
    "        results.loc[index,\"headline_word_count\"] = len(headline_words)\n",
    "        results.loc[index,\"headline_unique_words_count\"] = len(set(headline_words))\n",
    "        results.loc[index,\"headline_sentence_count\"] = len(norm_headline)\n",
    "        headline_lemmas = get_article_lemmas(norm_headline)\n",
    "        results.loc[index,\"headline_lemmas_count\"] = len(headline_lemmas)\n",
    "        results.loc[index,\"headline_unique_lemmas_count\"] = len(set(headline_lemmas))\n",
    "        words_for_all_headlines += headline_words\n",
    "        lemmas_for_all_headlines += headline_lemmas\n",
    "        \n",
    "        article = df['article_text'][index]\n",
    "        norm_article = get_normalized_sentences(article)\n",
    "        article_words = get_article_tokens(norm_article)\n",
    "        results.loc[index,\"article_word_count\"] = len(article_words)\n",
    "        results.loc[index,\"article_unique_words_count\"] = len(set(article_words))\n",
    "        results.loc[index,\"article_sentence_count\"] = len(norm_article)\n",
    "        article_lemmas = get_article_lemmas(norm_article)\n",
    "        results.loc[index,\"article_lemmas_count\"] = len(article_lemmas)\n",
    "        results.loc[index,\"article_unique_lemmas_count\"] = len(set(article_lemmas))\n",
    "        words_for_all_articles += article_words\n",
    "        lemmas_for_all_articles += article_lemmas\n",
    "\n",
    "        \n",
    "#     return results, words_for_all_headlines, lemmas_for_all_headlines, words_for_all_articles, lemmas_for_all_articles\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "mathematical-extraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stats = stats_per_group(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "assigned-consolidation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>headline_word_count</th>\n",
       "      <td>963.0</td>\n",
       "      <td>6.467290</td>\n",
       "      <td>1.235191</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headline_unique_words_count</th>\n",
       "      <td>963.0</td>\n",
       "      <td>6.463136</td>\n",
       "      <td>1.233389</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headline_sentence_count</th>\n",
       "      <td>963.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headline_lemmas_count</th>\n",
       "      <td>963.0</td>\n",
       "      <td>6.988577</td>\n",
       "      <td>1.639201</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headline_unique_lemmas_count</th>\n",
       "      <td>963.0</td>\n",
       "      <td>6.760125</td>\n",
       "      <td>1.399283</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_word_count</th>\n",
       "      <td>963.0</td>\n",
       "      <td>343.263759</td>\n",
       "      <td>279.043393</td>\n",
       "      <td>18.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>257.0</td>\n",
       "      <td>386.0</td>\n",
       "      <td>3189.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_unique_words_count</th>\n",
       "      <td>963.0</td>\n",
       "      <td>253.218069</td>\n",
       "      <td>184.508602</td>\n",
       "      <td>18.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>284.5</td>\n",
       "      <td>2119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_sentence_count</th>\n",
       "      <td>963.0</td>\n",
       "      <td>2.660436</td>\n",
       "      <td>2.383232</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_lemmas_count</th>\n",
       "      <td>963.0</td>\n",
       "      <td>139.322949</td>\n",
       "      <td>123.234360</td>\n",
       "      <td>3.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>1289.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_unique_lemmas_count</th>\n",
       "      <td>963.0</td>\n",
       "      <td>90.161994</td>\n",
       "      <td>67.668330</td>\n",
       "      <td>3.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>668.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              count        mean         std   min    25%  \\\n",
       "headline_word_count           963.0    6.467290    1.235191   2.0    6.0   \n",
       "headline_unique_words_count   963.0    6.463136    1.233389   2.0    6.0   \n",
       "headline_sentence_count       963.0    1.000000    0.000000   1.0    1.0   \n",
       "headline_lemmas_count         963.0    6.988577    1.639201   1.0    6.0   \n",
       "headline_unique_lemmas_count  963.0    6.760125    1.399283   1.0    6.0   \n",
       "article_word_count            963.0  343.263759  279.043393  18.0  197.0   \n",
       "article_unique_words_count    963.0  253.218069  184.508602  18.0  153.0   \n",
       "article_sentence_count        963.0    2.660436    2.383232   1.0    1.0   \n",
       "article_lemmas_count          963.0  139.322949  123.234360   3.0   38.0   \n",
       "article_unique_lemmas_count   963.0   90.161994   67.668330   3.0   35.0   \n",
       "\n",
       "                                50%    75%     max  \n",
       "headline_word_count             7.0    7.0    10.0  \n",
       "headline_unique_words_count     7.0    7.0    10.0  \n",
       "headline_sentence_count         1.0    1.0     1.0  \n",
       "headline_lemmas_count           7.0    8.0    14.0  \n",
       "headline_unique_lemmas_count    7.0    8.0    11.0  \n",
       "article_word_count            257.0  386.0  3189.0  \n",
       "article_unique_words_count    197.0  284.5  2119.0  \n",
       "article_sentence_count          2.0    3.0    28.0  \n",
       "article_lemmas_count          108.0  214.0  1289.0  \n",
       "article_unique_lemmas_count    81.0  129.0   668.0  "
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stats.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "religious-curtis",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "banned-livestock",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_stats = stats_per_group(validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "tired-directive",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>headline_word_count</th>\n",
       "      <td>321.0</td>\n",
       "      <td>6.401869</td>\n",
       "      <td>1.174147</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headline_unique_words_count</th>\n",
       "      <td>321.0</td>\n",
       "      <td>6.401869</td>\n",
       "      <td>1.174147</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headline_sentence_count</th>\n",
       "      <td>321.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headline_lemmas_count</th>\n",
       "      <td>321.0</td>\n",
       "      <td>6.816199</td>\n",
       "      <td>1.575353</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headline_unique_lemmas_count</th>\n",
       "      <td>321.0</td>\n",
       "      <td>6.623053</td>\n",
       "      <td>1.373169</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_word_count</th>\n",
       "      <td>321.0</td>\n",
       "      <td>399.834891</td>\n",
       "      <td>619.928621</td>\n",
       "      <td>19.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>257.0</td>\n",
       "      <td>409.0</td>\n",
       "      <td>6322.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_unique_words_count</th>\n",
       "      <td>321.0</td>\n",
       "      <td>279.993769</td>\n",
       "      <td>325.769023</td>\n",
       "      <td>19.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>3081.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_sentence_count</th>\n",
       "      <td>321.0</td>\n",
       "      <td>3.274143</td>\n",
       "      <td>7.127823</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_lemmas_count</th>\n",
       "      <td>321.0</td>\n",
       "      <td>136.261682</td>\n",
       "      <td>117.757670</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>1115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_unique_lemmas_count</th>\n",
       "      <td>321.0</td>\n",
       "      <td>87.971963</td>\n",
       "      <td>65.421727</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>627.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              count        mean         std   min    25%  \\\n",
       "headline_word_count           321.0    6.401869    1.174147   3.0    6.0   \n",
       "headline_unique_words_count   321.0    6.401869    1.174147   3.0    6.0   \n",
       "headline_sentence_count       321.0    1.000000    0.000000   1.0    1.0   \n",
       "headline_lemmas_count         321.0    6.816199    1.575353   3.0    6.0   \n",
       "headline_unique_lemmas_count  321.0    6.623053    1.373169   3.0    6.0   \n",
       "article_word_count            321.0  399.834891  619.928621  19.0  197.0   \n",
       "article_unique_words_count    321.0  279.993769  325.769023  19.0  149.0   \n",
       "article_sentence_count        321.0    3.274143    7.127823   1.0    1.0   \n",
       "article_lemmas_count          321.0  136.261682  117.757670   1.0   39.0   \n",
       "article_unique_lemmas_count   321.0   87.971963   65.421727   1.0   36.0   \n",
       "\n",
       "                                50%    75%     max  \n",
       "headline_word_count             6.0    7.0    10.0  \n",
       "headline_unique_words_count     6.0    7.0    10.0  \n",
       "headline_sentence_count         1.0    1.0     1.0  \n",
       "headline_lemmas_count           7.0    8.0    11.0  \n",
       "headline_unique_lemmas_count    7.0    7.0    10.0  \n",
       "article_word_count            257.0  409.0  6322.0  \n",
       "article_unique_words_count    198.0  291.0  3081.0  \n",
       "article_sentence_count          2.0    3.0    73.0  \n",
       "article_lemmas_count          105.0  214.0  1115.0  \n",
       "article_unique_lemmas_count    78.0  126.0   627.0  "
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_stats.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "alert-dinner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>19</th>\n",
       "      <th>1312</th>\n",
       "      <th>466</th>\n",
       "      <th>1524</th>\n",
       "      <th>379</th>\n",
       "      <th>118</th>\n",
       "      <th>169</th>\n",
       "      <th>442</th>\n",
       "      <th>988</th>\n",
       "      <th>570</th>\n",
       "      <th>...</th>\n",
       "      <th>814</th>\n",
       "      <th>985</th>\n",
       "      <th>1447</th>\n",
       "      <th>116</th>\n",
       "      <th>639</th>\n",
       "      <th>71</th>\n",
       "      <th>934</th>\n",
       "      <th>1595</th>\n",
       "      <th>815</th>\n",
       "      <th>103</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>headline_word_count</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headline_unique_words_count</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headline_sentence_count</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headline_lemmas_count</th>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headline_unique_lemmas_count</th>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_word_count</th>\n",
       "      <td>256.0</td>\n",
       "      <td>713.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>...</td>\n",
       "      <td>343.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>316.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>758.0</td>\n",
       "      <td>776.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_unique_words_count</th>\n",
       "      <td>199.0</td>\n",
       "      <td>515.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>...</td>\n",
       "      <td>248.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>541.0</td>\n",
       "      <td>630.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_sentence_count</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_lemmas_count</th>\n",
       "      <td>262.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>...</td>\n",
       "      <td>73.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>316.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>352.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_unique_lemmas_count</th>\n",
       "      <td>165.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>59.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>259.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 322 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               19     1312   466    1524   379    118    169   \\\n",
       "headline_word_count             7.0    7.0    6.0    6.0    7.0    6.0    6.0   \n",
       "headline_unique_words_count     7.0    7.0    6.0    6.0    7.0    6.0    6.0   \n",
       "headline_sentence_count         1.0    1.0    1.0    1.0    1.0    1.0    1.0   \n",
       "headline_lemmas_count           9.0    7.0    7.0    7.0    8.0    6.0    7.0   \n",
       "headline_unique_lemmas_count    9.0    7.0    7.0    7.0    8.0    6.0    6.0   \n",
       "article_word_count            256.0  713.0  245.0  190.0  164.0  171.0  114.0   \n",
       "article_unique_words_count    199.0  515.0  197.0  135.0  118.0  125.0   90.0   \n",
       "article_sentence_count          1.0    6.0    2.0    1.0    2.0    2.0    1.0   \n",
       "article_lemmas_count          262.0   49.0   75.0  223.0    7.0   40.0  143.0   \n",
       "article_unique_lemmas_count   165.0   40.0   61.0  119.0    7.0   36.0   78.0   \n",
       "\n",
       "                               442    988    570   ...   814   985    1447  \\\n",
       "headline_word_count             8.0    5.0    7.0  ...    8.0   7.0    7.0   \n",
       "headline_unique_words_count     8.0    5.0    7.0  ...    8.0   7.0    7.0   \n",
       "headline_sentence_count         1.0    1.0    1.0  ...    1.0   1.0    1.0   \n",
       "headline_lemmas_count           9.0    5.0    6.0  ...    7.0   6.0    9.0   \n",
       "headline_unique_lemmas_count    9.0    5.0    6.0  ...    7.0   6.0    8.0   \n",
       "article_word_count            200.0  277.0  307.0  ...  343.0  24.0  155.0   \n",
       "article_unique_words_count    139.0  229.0  239.0  ...  248.0  23.0  132.0   \n",
       "article_sentence_count          1.0    6.0    2.0  ...    5.0   1.0    1.0   \n",
       "article_lemmas_count          222.0   67.0   72.0  ...   73.0  28.0  173.0   \n",
       "article_unique_lemmas_count   112.0   57.0   64.0  ...   59.0  22.0  108.0   \n",
       "\n",
       "                               116    639    71     934    1595   815    103   \n",
       "headline_word_count            10.0    7.0    6.0    8.0    5.0    7.0    5.0  \n",
       "headline_unique_words_count    10.0    7.0    6.0    8.0    5.0    7.0    5.0  \n",
       "headline_sentence_count         1.0    1.0    1.0    1.0    1.0    1.0    1.0  \n",
       "headline_lemmas_count          10.0    4.0    6.0    7.0    6.0    7.0    3.0  \n",
       "headline_unique_lemmas_count   10.0    4.0    6.0    7.0    6.0    7.0    3.0  \n",
       "article_word_count            188.0  184.0  316.0  265.0  266.0  758.0  776.0  \n",
       "article_unique_words_count    149.0  153.0  265.0  222.0  208.0  541.0  630.0  \n",
       "article_sentence_count          1.0    1.0    1.0    2.0    2.0   10.0    2.0  \n",
       "article_lemmas_count          205.0  197.0  316.0   17.0   89.0   13.0  352.0  \n",
       "article_unique_lemmas_count   123.0  135.0  201.0   17.0   74.0   13.0  259.0  \n",
       "\n",
       "[10 rows x 322 columns]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_stats = stats_per_group(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "particular-texture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>headline_word_count</th>\n",
       "      <td>322.0</td>\n",
       "      <td>6.537267</td>\n",
       "      <td>1.199757</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headline_unique_words_count</th>\n",
       "      <td>322.0</td>\n",
       "      <td>6.531056</td>\n",
       "      <td>1.202528</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headline_sentence_count</th>\n",
       "      <td>322.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headline_lemmas_count</th>\n",
       "      <td>322.0</td>\n",
       "      <td>7.024845</td>\n",
       "      <td>1.666792</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headline_unique_lemmas_count</th>\n",
       "      <td>322.0</td>\n",
       "      <td>6.791925</td>\n",
       "      <td>1.452315</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_word_count</th>\n",
       "      <td>322.0</td>\n",
       "      <td>348.689441</td>\n",
       "      <td>271.468735</td>\n",
       "      <td>24.0</td>\n",
       "      <td>192.00</td>\n",
       "      <td>262.0</td>\n",
       "      <td>400.50</td>\n",
       "      <td>2674.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_unique_words_count</th>\n",
       "      <td>322.0</td>\n",
       "      <td>256.732919</td>\n",
       "      <td>179.811004</td>\n",
       "      <td>23.0</td>\n",
       "      <td>152.00</td>\n",
       "      <td>202.5</td>\n",
       "      <td>290.75</td>\n",
       "      <td>1719.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_sentence_count</th>\n",
       "      <td>322.0</td>\n",
       "      <td>2.913043</td>\n",
       "      <td>2.617676</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_lemmas_count</th>\n",
       "      <td>322.0</td>\n",
       "      <td>134.574534</td>\n",
       "      <td>125.754182</td>\n",
       "      <td>2.0</td>\n",
       "      <td>38.25</td>\n",
       "      <td>100.5</td>\n",
       "      <td>208.75</td>\n",
       "      <td>1125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_unique_lemmas_count</th>\n",
       "      <td>322.0</td>\n",
       "      <td>87.108696</td>\n",
       "      <td>69.170321</td>\n",
       "      <td>2.0</td>\n",
       "      <td>33.25</td>\n",
       "      <td>77.5</td>\n",
       "      <td>124.75</td>\n",
       "      <td>593.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              count        mean         std   min     25%  \\\n",
       "headline_word_count           322.0    6.537267    1.199757   3.0    6.00   \n",
       "headline_unique_words_count   322.0    6.531056    1.202528   3.0    6.00   \n",
       "headline_sentence_count       322.0    1.000000    0.000000   1.0    1.00   \n",
       "headline_lemmas_count         322.0    7.024845    1.666792   3.0    6.00   \n",
       "headline_unique_lemmas_count  322.0    6.791925    1.452315   3.0    6.00   \n",
       "article_word_count            322.0  348.689441  271.468735  24.0  192.00   \n",
       "article_unique_words_count    322.0  256.732919  179.811004  23.0  152.00   \n",
       "article_sentence_count        322.0    2.913043    2.617676   1.0    1.00   \n",
       "article_lemmas_count          322.0  134.574534  125.754182   2.0   38.25   \n",
       "article_unique_lemmas_count   322.0   87.108696   69.170321   2.0   33.25   \n",
       "\n",
       "                                50%     75%     max  \n",
       "headline_word_count             7.0    7.00    11.0  \n",
       "headline_unique_words_count     7.0    7.00    11.0  \n",
       "headline_sentence_count         1.0    1.00     1.0  \n",
       "headline_lemmas_count           7.0    8.00    12.0  \n",
       "headline_unique_lemmas_count    7.0    8.00    11.0  \n",
       "article_word_count            262.0  400.50  2674.0  \n",
       "article_unique_words_count    202.5  290.75  1719.0  \n",
       "article_sentence_count          2.0    4.00    15.0  \n",
       "article_lemmas_count          100.5  208.75  1125.0  \n",
       "article_unique_lemmas_count    77.5  124.75   593.0  "
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_stats.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "entertaining-absorption",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(dataset_name ,words_for_all_headlines, lemmas_for_all_headlines, words_for_all_articles, lemmas_for_all_articles):\n",
    "    headline_lemmas = [i.strip() for i in lemmas_for_all_headlines]\n",
    "    headline_words = [i.strip() for i in words_for_all_headlines]\n",
    "    articles_lemmas = [i.strip() for i in lemmas_for_all_articles]\n",
    "    articles_words = [i.strip() for i in words_for_all_articles]\n",
    "    \n",
    "    count_article_unique_words = len(set(articles_words))\n",
    "    count_article_unique_lemmas = len(set(articles_lemmas))\n",
    "    count_headline_unique_words = len(set(headline_words))\n",
    "    count_headline_unique_lemmas = len(set(headline_lemmas))\n",
    "    \n",
    "    common_unique_lemmas = set.intersection(set(headline_lemmas), set(articles_lemmas))\n",
    "    print('+' * 10, dataset_name, '+' * 10)\n",
    "    print(\"=\"*5,'Summary Lemmas {}'.format(len(headline_lemmas)))\n",
    "    print(\"=\"*5,'Summary Words {}'.format(len(headline_words)))\n",
    "    print(\"=\"*5,'Article Lemmas {}'.format(len(articles_lemmas)))\n",
    "    print(\"=\"*5,'Article Words {}'.format(len(articles_words)))\n",
    "    print('.'*20)\n",
    "    print(\"=\"*5,'Common Unique Lemmas {}'.format(len(common_unique_lemmas)))\n",
    "    print(\"=\"*5,'Summary Unique Lemmas {}'.format(count_headline_unique_lemmas))\n",
    "    print(\"=\"*5,'Summary Unique Words {}'.format(count_headline_unique_words))\n",
    "    print(\"=\"*5,'Article Unique Lemmas {}'.format(count_article_unique_lemmas))\n",
    "    print(\"=\"*5,'Article Unique Words {}'.format(count_article_unique_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "automated-multimedia",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stats, words_for_all_headlines, lemmas_for_all_headlines, words_for_all_articles, lemmas_for_all_articles = stats_per_group(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "light-elizabeth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++ Train Dataset ++++++++++\n",
      "===== Number of Summary Lemmas 6730\n",
      "===== Number of Summary Words 6228\n",
      "===== Number of Article Lemmas 134168\n",
      "===== Number of Article Words 6228\n",
      "===== Number of Common Unique Lemmas 2142\n",
      "....................\n",
      "===== Number of Summary Unique Lemmas 2345\n",
      "===== Number of Summary Unique Words 3530\n",
      "===== Number of Article Unique Lemmas 13140\n",
      "===== Number of Article Unique Words 3530\n"
     ]
    }
   ],
   "source": [
    "print_stats('Train Dataset', words_for_all_headlines, lemmas_for_all_headlines, words_for_all_articles, lemmas_for_all_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "naked-idaho",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_stats, words_for_all_headlines, lemmas_for_all_headlines, words_for_all_articles, lemmas_for_all_articles = stats_per_group(validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "moved-course",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++ Validate Dataset ++++++++++\n",
      "===== Number of Summary Lemmas 2188\n",
      "===== Number of Summary Words 2055\n",
      "===== Number of Article Lemmas 43740\n",
      "===== Number of Article Words 128347\n",
      "===== Number of Common Unique Lemmas 1012\n",
      "....................\n",
      "===== Number of Summary Unique Lemmas 1114\n",
      "===== Number of Summary Unique Words 1468\n",
      "===== Number of Article Unique Lemmas 7112\n",
      "===== Number of Article Unique Words 28137\n"
     ]
    }
   ],
   "source": [
    "print_stats('Validate Dataset', words_for_all_headlines, lemmas_for_all_headlines, words_for_all_articles, lemmas_for_all_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "norman-conference",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stats, words_for_all_headlines, lemmas_for_all_headlines, words_for_all_articles, lemmas_for_all_articles = stats_per_group(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dried-vitamin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++ Test Dataset ++++++++++\n",
      "===== Number of Summary Lemmas 2262\n",
      "===== Number of Summary Words 2105\n",
      "===== Number of Article Lemmas 43333\n",
      "===== Number of Article Words 112278\n",
      "===== Number of Common Unique Lemmas 1020\n",
      "....................\n",
      "===== Number of Summary Unique Lemmas 1139\n",
      "===== Number of Summary Unique Words 1488\n",
      "===== Number of Article Unique Lemmas 6983\n",
      "===== Number of Article Unique Words 26504\n"
     ]
    }
   ],
   "source": [
    "print_stats('Test Dataset', words_for_all_headlines, lemmas_for_all_headlines, words_for_all_articles, lemmas_for_all_articles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
